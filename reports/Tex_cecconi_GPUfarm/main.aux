\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:intro}{{1}{1}{Introduction}{chapter.1}{}}
\citation{pattersonhennessy}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Goals}{2}{section.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}GPU Architecture and Data Parallel}{2}{subsection.1.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Other Applications}{2}{subsection.1.1.2}}
\newlabel{subs:otherApps}{{1.1.2}{2}{Other Applications}{subsection.1.1.2}{}}
\citation{fromCUtoOCL}
\citation{backtrack}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}GP-GPUs and Stream Parallel}{4}{subsection.1.1.3}}
\citation{spm}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Expectations}{5}{section.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Results}{6}{section.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Tools}{6}{section.1.4}}
\newlabel{sect:tools}{{1.4}{6}{Tools}{section.1.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Tools}{9}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:tools}{{2}{9}{Tools}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}CUDA}{10}{section.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces GPUs specifics for the two remote machines employed in this project.\relax }}{11}{table.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:gpuspecs}{{2.1}{11}{GPUs specifics for the two remote machines employed in this project.\relax }{table.caption.1}{}}
\citation{cudaguide}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces GPU scalability.\relax }}{12}{figure.caption.2}}
\newlabel{fig:cudaSM}{{2.1}{12}{GPU scalability.\relax }{figure.caption.2}{}}
\citation{profilersguide}
\citation{nvprofarticle}
\citation{profilersguide}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Profilers}{13}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}nvprof}{13}{subsection.2.2.1}}
\citation{profilersguide}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}NVIDIA Visual Profiler}{14}{subsection.2.2.2}}
\citation{cudaguide}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}CUDA C/C++}{15}{section.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Above: a Grid formed by Blocks.  Below: a Block formed by Threads.\relax }}{15}{figure.caption.3}}
\newlabel{fig:gridblock}{{2.2}{15}{Above: a Grid formed by Blocks.\\ Below: a Block formed by Threads.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Kernels}{15}{subsection.2.3.1}}
\newlabel{subs:ker}{{2.3.1}{15}{Kernels}{subsection.2.3.1}{}}
\citation{cudaguide}
\citation{cudaguide}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Thread Hierarchy}{16}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}CUDA Streams}{16}{subsection.2.3.3}}
\newlabel{subs:streams}{{2.3.3}{16}{CUDA Streams}{subsection.2.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}nvcc compiler}{18}{subsection.2.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}\texttt  {cuda-gdb} debugger}{19}{subsection.2.3.5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Visual Studio Code}{20}{section.2.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Tests, Result gathering, Plots}{20}{section.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Bash scripts}{21}{subsection.2.5.1}}
\newlabel{subs:bash}{{2.5.1}{21}{Bash scripts}{subsection.2.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Python scripts}{21}{subsection.2.5.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Project Logic}{22}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:logic}{{3}{22}{Project Logic}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Streaming Parallelism: Farm pattern}{22}{section.3.1}}
\citation{spm}
\citation{spm}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}CPU-GPGPU: heterogeneous architecture}{24}{section.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Overlapping: Data Transfer hiding}{25}{subsection.3.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Ideal behavior for 3 CUDA Streams.\relax }}{26}{figure.caption.4}}
\newlabel{fig:threeStreams}{{3.1}{26}{Ideal behavior for 3 CUDA Streams.\relax }{figure.caption.4}{}}
\citation{cudaguide}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Occupancy of GPU cores}{28}{subsection.3.2.2}}
\citation{cudaguide}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Occupancy drawbacks}{30}{subsection.3.2.3}}
\citation{loweroccupancy}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Overall Logic}{32}{section.3.3}}
\newlabel{sect:overallLogica}{{3.3}{32}{Overall Logic}{section.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Here we have a general and broad graphical representation of our idea on how to fit a Farm parallel pattern on GPU architecture.\relax }}{33}{figure.caption.5}}
\newlabel{fig:H2D}{{3.2}{33}{Here we have a general and broad graphical representation of our idea on how to fit a Farm parallel pattern on GPU architecture.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Here we have a general and broad graphical representation of our idea on how to fit a Farm parallel pattern on GPU architecture.\relax }}{35}{figure.caption.6}}
\newlabel{fig:overallLogic}{{3.3}{35}{Here we have a general and broad graphical representation of our idea on how to fit a Farm parallel pattern on GPU architecture.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Legenda about Figure \ref  {fig:overallLogic}.\relax }}{37}{figure.caption.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Here we can see what exactly happens in a certain CUDA Stream. Light violet numbered labels shows the order in which commands are issued by host to a certain stream.\relax }}{39}{figure.caption.8}}
\newlabel{fig:singleStream}{{3.5}{39}{Here we can see what exactly happens in a certain CUDA Stream. Light violet numbered labels shows the order in which commands are issued by host to a certain stream.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Tunings}{39}{section.3.4}}
\newlabel{sect:tunings}{{3.4}{39}{Tunings}{section.3.4}{}}
\citation{cudaguide}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Tuning on block and grid dimensions}{41}{subsection.3.4.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}CPU/GPU Scheduling}{42}{section.3.5}}
\newlabel{sect:cpugpuscheduling}{{3.5}{42}{CPU/GPU Scheduling}{section.3.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Implementation}{44}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:impl}{{4}{44}{Implementation}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Kernels}{44}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Repeated cosine}{45}{subsection.4.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Matrix multiplication}{45}{subsection.4.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Blur Box filter}{47}{subsection.4.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Parallel Patterns implementation on GPU}{48}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Stream Parallel on GPU}{48}{subsection.4.2.1}}
\newlabel{lst:noStr}{{4.2.1}{49}{}{lstlisting.4.-11}{}}
\newlabel{lst:str}{{4.2.1}{50}{}{lstlisting.4.-12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Data Parallel un GPU}{52}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}CPU and GPU Mix}{54}{section.4.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Experiments}{55}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:experim}{{5}{55}{Experiments}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Expectations}{55}{section.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Measures: What and How}{56}{subsection.5.1.1}}
\newlabel{lst:timers}{{5.1.1}{57}{}{lstlisting.5.-15}{}}
\citation{devblogevents}
\citation{libevents}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Tests setup}{61}{subsection.5.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Speedup}{62}{subsection.5.1.3}}
\newlabel{susb:speedup}{{5.1.3}{62}{Speedup}{subsection.5.1.3}{}}
\citation{structparprog}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}Results gathering and modeling}{67}{subsection.5.1.4}}
\newlabel{subs:resgath}{{5.1.4}{67}{Results gathering and modeling}{subsection.5.1.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Simple-computation kernel}{68}{section.5.2}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Input dataset for Simple-Computation kernel, these are the input stream length for both devices.\relax }}{69}{table.caption.9}}
\newlabel{tab:cosdata}{{5.1}{69}{Input dataset for Simple-Computation kernel, these are the input stream length for both devices.\relax }{table.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Results}{72}{subsection.5.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Device completion times for Simple-computation kernel, without using CUDA Streams, results are reported for both machines (P100 and M40).\relax }}{73}{table.caption.10}}
\newlabel{tab:cosavgszero}{{5.2}{73}{Device completion times for Simple-computation kernel, without using CUDA Streams, results are reported for both machines (P100 and M40).\relax }{table.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Device completion times for Simple-computation kernel, using as many CUDA Streams as SM number, results are reported for both machines (P100 and M40).\relax }}{74}{table.caption.11}}
\newlabel{tab:cosavgsSM}{{5.3}{74}{Device completion times for Simple-computation kernel, using as many CUDA Streams as SM number, results are reported for both machines (P100 and M40).\relax }{table.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Here are showed speedups for all data sets of simple-computation kernel. Results are reported for both devices.\relax }}{76}{table.caption.12}}
\newlabel{tab:cosspeedup}{{5.4}{76}{Here are showed speedups for all data sets of simple-computation kernel. Results are reported for both devices.\relax }{table.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Speedup for 3 and 56 CUDA streams on P100 device.\relax }}{77}{figure.caption.13}}
\newlabel{fig:p100sp}{{5.1}{77}{Speedup for 3 and 56 CUDA streams on P100 device.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Speedup for 3 and 56 CUDA streams on M40 device.\relax }}{77}{figure.caption.13}}
\newlabel{fig:m40sp}{{5.2}{77}{Speedup for 3 and 56 CUDA streams on M40 device.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Matrix Multiplication}{78}{section.5.3}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces Input dataset for Matrix Multiplication kernel. Above Stream parallel configuration, below Data Parallel correspondent.\relax }}{79}{table.caption.14}}
\newlabel{tab:matdata}{{5.5}{79}{Input dataset for Matrix Multiplication kernel. Above Stream parallel configuration, below Data Parallel correspondent.\relax }{table.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Results}{81}{subsection.5.3.1}}
\@writefile{lot}{\contentsline {table}{\numberline {5.6}{\ignorespaces Device completion times for Mat-Mul kernel, without using CUDA Streams (zero streams), results are reported for both P100 and M40.\relax }}{82}{table.caption.15}}
\newlabel{tab:matvgszero}{{5.6}{82}{Device completion times for Mat-Mul kernel, without using CUDA Streams (zero streams), results are reported for both P100 and M40.\relax }{table.caption.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.7}{\ignorespaces Device completion times for Mat-Mul kernel, with three CUDA Streams, results are reported for both P100 and M40.\relax }}{83}{table.caption.16}}
\newlabel{tab:matvgsThree}{{5.7}{83}{Device completion times for Mat-Mul kernel, with three CUDA Streams, results are reported for both P100 and M40.\relax }{table.caption.16}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.8}{\ignorespaces Device completion times for Mat-Mul kernel, with as many CUDA Streams as SM number, results are reported for both P100 and M40.\relax }}{84}{table.caption.17}}
\newlabel{tab:matvgsSM}{{5.8}{84}{Device completion times for Mat-Mul kernel, with as many CUDA Streams as SM number, results are reported for both P100 and M40.\relax }{table.caption.17}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.9}{\ignorespaces Here are showed speedups for all data sets of simple-computation kernel. Results are reported for both devices.\relax }}{86}{table.caption.18}}
\newlabel{tab:matspeedup}{{5.9}{86}{Here are showed speedups for all data sets of simple-computation kernel. Results are reported for both devices.\relax }{table.caption.18}{}}
\newlabel{fig:timeln256}{{5.3a}{88}{Subfigure 5 5.3a}{subfigure.5.3.1}{}}
\newlabel{sub@fig:timeln256}{{(a)}{a}{Subfigure 5 5.3a\relax }{subfigure.5.3.1}{}}
\newlabel{fig:timeln1024}{{5.3b}{88}{Subfigure 5 5.3b}{subfigure.5.3.2}{}}
\newlabel{sub@fig:timeln1024}{{(b)}{b}{Subfigure 5 5.3b\relax }{subfigure.5.3.2}{}}
\newlabel{fig:timeln64}{{5.3c}{88}{Subfigure 5 5.3c}{subfigure.5.3.3}{}}
\newlabel{sub@fig:timeln64}{{(c)}{c}{Subfigure 5 5.3c\relax }{subfigure.5.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces NVIDIA Visual profiler generated \textit  {timeline} on M40, using 24 CUDA streams and running code for 784 matrices.\relax }}{88}{figure.caption.19}}
\newlabel{fig:timeln}{{5.3}{88}{NVIDIA Visual profiler generated \textit {timeline} on M40, using 24 CUDA streams and running code for 784 matrices.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Matrix size 256}}}{88}{subfigure.3.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Matrix size 1024}}}{88}{subfigure.3.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Matrix size 64}}}{88}{subfigure.3.3}}
\citation{loweroccupancy}
\newlabel{fig:SMuse64}{{5.4a}{89}{Subfigure 5 5.4a}{subfigure.5.4.1}{}}
\newlabel{sub@fig:SMuse64}{{(a)}{a}{Subfigure 5 5.4a\relax }{subfigure.5.4.1}{}}
\newlabel{fig:SMuse1024}{{5.4b}{89}{Subfigure 5 5.4b}{subfigure.5.4.2}{}}
\newlabel{sub@fig:SMuse1024}{{(b)}{b}{Subfigure 5 5.4b\relax }{subfigure.5.4.2}{}}
\newlabel{fig:SMuse256}{{5.4c}{89}{Subfigure 5 5.4c}{subfigure.5.4.3}{}}
\newlabel{sub@fig:SMuse256}{{(c)}{c}{Subfigure 5 5.4c\relax }{subfigure.5.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces NVIDIA Visual profiler generated \textit  {timeline} on M40, using 24 CUDA streams and running code for 784 matrices.\relax }}{89}{figure.caption.20}}
\newlabel{fig:SMuse}{{5.4}{89}{NVIDIA Visual profiler generated \textit {timeline} on M40, using 24 CUDA streams and running code for 784 matrices.\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Matrix size 64}}}{89}{subfigure.4.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Matrix size 1024}}}{89}{subfigure.4.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Matrix size 256}}}{89}{subfigure.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Nsight profiler execution on M40, 24 CUDA streams, 784 matrices of size 256. This graph gives the types and relative amounts of latencies inside our mat-mul kernel code.\relax }}{90}{figure.caption.21}}
\newlabel{fig:mat62latency}{{5.5}{90}{Nsight profiler execution on M40, 24 CUDA streams, 784 matrices of size 256. This graph gives the types and relative amounts of latencies inside our mat-mul kernel code.\relax }{figure.caption.21}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.10}{\ignorespaces Input dataset for Image Processing kernel. Above Stream parallel configuration, below Data Parallel correspondent.\relax }}{91}{table.caption.22}}
\newlabel{tab:imgdata}{{5.10}{91}{Input dataset for Image Processing kernel. Above Stream parallel configuration, below Data Parallel correspondent.\relax }{table.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Image processing}{91}{section.5.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Results Summary}{92}{section.5.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Simple-computation kernel}{92}{subsection.5.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Matrix Multiplication}{93}{subsection.5.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Image Processing}{93}{subsection.5.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Plots}{93}{section.5.6}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusions}{94}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:conclusions}{{6}{94}{Conclusions}{chapter.6}{}}
\bibcite{pattersonhennessy}{1}
\bibcite{fromCUtoOCL}{2}
\bibcite{backtrack}{3}
\bibcite{spm}{4}
\bibcite{cudaguide}{5}
\bibcite{profilersguide}{6}
\bibcite{nvprofarticle}{7}
\bibcite{loweroccupancy}{8}
\bibcite{devblogevents}{9}
\bibcite{libevents}{10}
\bibcite{structparprog}{11}
