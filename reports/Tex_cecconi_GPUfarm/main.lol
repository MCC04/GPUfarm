\contentsline {lstlisting}{\numberline {2.1}CUDA Strams creation}{26}{lstlisting.2.1}
\contentsline {lstlisting}{\numberline {2.2}CUDA Strams and Async example}{27}{lstlisting.2.2}
\contentsline {lstlisting}{\numberline {2.3}Tests on bash scripts example}{32}{lstlisting.2.3}
\contentsline {lstlisting}{\numberline {2.4}Portion of speedup and plots Python script}{33}{lstlisting.2.4}
\contentsline {lstlisting}{\numberline {4.1}Implementation for Simple-Computation Kernel}{64}{lstlisting.4.1}
\contentsline {lstlisting}{\numberline {4.2}Implementation for Matrix Multiplication Kernel, both non-square and square}{65}{lstlisting.4.2}
\contentsline {lstlisting}{\numberline {4.3}Implementation for Image processing Kernel (Blur Box Algorithm)}{67}{lstlisting.4.3}
\contentsline {lstlisting}{\numberline {4.4}Simple-computational Kernel Launch configuration, i.e. Grid and Block dimensions setting}{70}{lstlisting.4.4}
\contentsline {lstlisting}{\numberline {4.5}Data transfer host/device and kernel call, synchronous version}{71}{lstlisting.4.5}
\contentsline {lstlisting}{\numberline {4.6}Data transfer host/device and kernel call, CUDA Streams version}{72}{lstlisting.4.6}
\contentsline {lstlisting}{\numberline {4.7}Host side pseudo-code: input stream \& kernel call function(scheduler).}{73}{lstlisting.4.7}
\contentsline {lstlisting}{\numberline {4.8}Optimal Kernel caller for Simple-Computation kernel, uses Occupancy APIs to get best Block configuration}{75}{lstlisting.4.8}
\contentsline {lstlisting}{\numberline {5.1}Example of code for events utilization as time probes.}{79}{lstlisting.5.1}
